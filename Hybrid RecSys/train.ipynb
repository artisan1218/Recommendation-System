{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "suffering-winter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import random\n",
    "from itertools import combinations \n",
    "import itertools\n",
    "import math\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from surprise import SVD, Reader, Dataset, dump\n",
    "import xgboost\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "harmful-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "\n",
    "#os.environ['PYSPARK_PYTHON'] = '/usr/local/bin/python3.6'\n",
    "#os.environ['PYSPARK_DRIVER_PYTHON'] = '/usr/local/bin/python3.6'\n",
    "\n",
    "conf = SparkConf().setMaster(\"local[*]\").set(\"spark.executor.memory\", \"4g\").set(\"spark.driver.memory\", \"4g\")\n",
    "sc = SparkContext(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "radio-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = r'C:\\Users\\11921\\Downloads\\competition\\train_review.json'\n",
    "friends_path = r'C:\\Users\\11921\\Downloads\\competition\\user.json'\n",
    "test_groundtruth_path = r'C:\\Users\\11921\\Downloads\\competition\\test_review_ratings.json'\n",
    "\n",
    "user_avg_file = r'C:\\Users\\11921\\Downloads\\competition\\user_avg.json'\n",
    "bus_avg_file = r'C:\\Users\\11921\\Downloads\\competition\\business_avg.json'\n",
    "user_file_path = r'C:\\Users\\11921\\Downloads\\competition\\user.json'\n",
    "\n",
    "xgb_model_output_path = r'xgb_model.json'\n",
    "SVD_model_output_path = r'svd_model.model'\n",
    "uid2idx_output_path = r'uid2idx_dict_model.txt'\n",
    "bid2idx_output_path = r'bid2idx_dict_model.txt'\n",
    "friends_output_path = r'friends_model.json'\n",
    "\n",
    "corated_threshold = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-aberdeen",
   "metadata": {},
   "source": [
    "### uid2idx_dict:\n",
    "keeps the mapping relation between unique userid to an user index, which is in this format:\\\n",
    "`\n",
    "{\n",
    " '8GWwu6gtDfAFfM2gehfPow': 0,\n",
    " 'JYcCYNWs8Ul6ewG5kCYW4Q': 1,\n",
    " 'woFthCAsX2JYi8i2qEBb1w': 2,\n",
    "}\n",
    "`\n",
    "\n",
    "### bid2idx_dict:\n",
    "keeps the mapping relation between unique businessid to an business index, which is in this format:\\\n",
    "`\n",
    "{\n",
    " '3xykzfVY2PbdjKCRDLdzTQ': 0,\n",
    " 'R7-Art-yi73tWaRTuXXH7w': 1,\n",
    " 'DYuOxkW4DtlJsTHdxdXSlg': 2,\n",
    "}\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "therapeutic-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonLine_rdd = sc.textFile(train_file_path).map(lambda line:json.loads(line)).persist()\n",
    "\n",
    "# read in the user/bus mapping dict\n",
    "use_test_gt = True\n",
    "if use_test_gt:\n",
    "    uid_index_train_rdd = jsonLine_rdd.map(lambda jLine:jLine['user_id']).distinct()\n",
    "    uid_index_gt_rdd = sc.textFile(test_groundtruth_path)\\\n",
    "                        .map(lambda line:json.loads(line))\\\n",
    "                        .map(lambda jLine:jLine['user_id']).distinct()\n",
    "    uid_index_rdd = uid_index_train_rdd.union(uid_index_gt_rdd).distinct().zipWithIndex()\n",
    "    \n",
    "    bid_index_train_rdd = jsonLine_rdd.map(lambda jLine:jLine['business_id']).distinct()\n",
    "    bid_index_gt_rdd = sc.textFile(test_groundtruth_path)\\\n",
    "                        .map(lambda line:json.loads(line))\\\n",
    "                        .map(lambda jLine:jLine['business_id']).distinct()\n",
    "    bid_index_rdd = bid_index_train_rdd.union(bid_index_gt_rdd).distinct().zipWithIndex()\n",
    "else:\n",
    "    uid_index_rdd = jsonLine_rdd.map(lambda jLine:jLine['user_id']).distinct().zipWithIndex()\n",
    "    bid_index_rdd = jsonLine_rdd.map(lambda jLine:jLine['business_id']).distinct().zipWithIndex()\n",
    "    \n",
    "uid2idx_dict = dict(uid_index_rdd.collect())\n",
    "bid2idx_dict = dict(bid_index_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "continuing-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputDictModel(id2idx_dict, path):\n",
    "    model_writer = open(path, 'w')\n",
    "    for ub_id in id2idx_dict:\n",
    "        line = str(ub_id) + ', ' + str(id2idx_dict[ub_id]) + '\\n'\n",
    "        model_writer.write(line)\n",
    "    model_writer.close()\n",
    "    \n",
    "outputDictModel(uid2idx_dict, uid2idx_output_path)\n",
    "outputDictModel(bid2idx_dict, bid2idx_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-sleeping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "essential-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKnownFriendsList(friends_list):\n",
    "    known_friends_idx = list()\n",
    "    for friend in friends_list:\n",
    "        fidx = str(uid2idx_dict.get(friend, 'UNK'))\n",
    "        if fidx != 'UNK':\n",
    "            known_friends_idx.append(fidx)\n",
    "    return known_friends_idx\n",
    "    \n",
    "\n",
    "# friends list\n",
    "friends = (sc.textFile(friends_path)\n",
    "           .map(lambda line:json.loads(line))\n",
    "           .map(lambda jLine:(jLine['user_id'], jLine['friends']))\n",
    "           .map(lambda pair: (uid2idx_dict.get(pair[0], pair[0]), pair[1].split(', ')))\n",
    "           .map(lambda pair:(str(pair[0]), getKnownFriendsList(pair[1])))\n",
    "           .collectAsMap()\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "convertible-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_writer = open(friends_output_path, 'w')\n",
    "for user in friends:\n",
    "    jLine = json.dumps({'u':user, 'friends':friends[user]})\n",
    "    model_writer.write(jLine + '\\n')\n",
    "model_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-emission",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-supply",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abstract-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_avg_dict = (sc.textFile(user_avg_file)\n",
    "                 .map(lambda line: json.loads(line))\n",
    "                 .flatMap(lambda kv_items: kv_items.items()) \n",
    "                 .map(lambda pair: (uid2idx_dict.get(pair[0], pair[0]), pair[1]))\n",
    "                 .collectAsMap()\n",
    "                )\n",
    "\n",
    "bus_avg_dict = (sc.textFile(bus_avg_file)\n",
    "                 .map(lambda line: json.loads(line))\n",
    "                 .flatMap(lambda kv_items: kv_items.items()) \n",
    "                 .map(lambda pair: (bid2idx_dict.get(pair[0], pair[0]), pair[1]))\n",
    "                 .collectAsMap()\n",
    "                )\n",
    "\n",
    "ALL_USER_AVG_RATING = sum(user_avg_dict.values())/len(user_avg_dict)\n",
    "ALL_BUS_AVG_RATING = sum(bus_avg_dict.values())/len(bus_avg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "spectacular-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the SVD algorithm using sklearn surprise\n",
    "uidx_bidx_star = (jsonLine_rdd.map(lambda jLine: (uid2idx_dict[jLine[\"user_id\"]],\n",
    "                                                  bid2idx_dict[jLine[\"business_id\"]], \n",
    "                                                  jLine[\"stars\"]\n",
    "                                                 )\n",
    "                                  )\n",
    "                  .collect()\n",
    "                 )\n",
    "\n",
    "random.seed(511)\n",
    "for _ in range(300000):\n",
    "    uidx = random.sample(uidx_bidx_star, 1)[0][0]\n",
    "    bidx = random.sample(uidx_bidx_star, 1)[0][1]\n",
    "    rating = user_avg_dict.get(uidx, bus_avg_dict.get(bidx, ALL_BUS_AVG_RATING))\n",
    "    up_sampling_pair = (uidx, bidx, rating)\n",
    "    uidx_bidx_star.append(up_sampling_pair)\n",
    "\n",
    "\n",
    "train_data_df = pd.DataFrame(uidx_bidx_star, columns=['uidx', 'bidx', 'rating'])\n",
    "\n",
    "reader = Reader()\n",
    "surprise_train_dataset = Dataset.load_from_df(train_data_df[['uidx', 'bidx', 'rating']], reader)\n",
    "trainset = surprise_train_dataset.build_full_trainset()\n",
    "\n",
    "svd_model = SVD(n_factors=10, biased=True, init_std_dev=0.05)\n",
    "svd_model.fit(trainset)\n",
    "\n",
    "dump.dump(SVD_model_output_path, predictions=None, algo=svd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-combat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-activity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-korea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "golden-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['uavg', 'bavg', 'useful', 'funny', 'cool', 'fans', 'user_num', 'bus_num', 'rating']\n",
    "default_tuple = (0,0,0,0)\n",
    "\n",
    "user_info_dict = (sc.textFile(user_file_path)\n",
    "                 .map(lambda line:json.loads(line))\n",
    "                 .map(lambda jLine:(uid2idx_dict.get(jLine['user_id'], jLine['user_id']), \n",
    "                                     (jLine['useful'], jLine['funny'], jLine['cool'], jLine['fans']\n",
    "                                     )))\n",
    "                 .collectAsMap()\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cardiac-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "uidx_star_dict = (sc.textFile(train_file_path).map(lambda line:json.loads(line))\n",
    "                       .map(lambda jLine:(jLine['user_id'], jLine['stars']))\n",
    "                       .map(lambda pair:(str(uid2idx_dict[pair[0]]), pair[1]))\n",
    "                       .groupByKey()\n",
    "                       .mapValues(lambda listOfTuple:list(listOfTuple))\n",
    "                       .collectAsMap()\n",
    "                      )\n",
    "\n",
    "bidx_star_dict = (sc.textFile(train_file_path).map(lambda line:json.loads(line))\n",
    "                       .map(lambda jLine:(jLine['business_id'], jLine['stars']))\n",
    "                       .map(lambda pair:(str(bid2idx_dict[pair[0]]), pair[1]))\n",
    "                       .groupByKey()\n",
    "                       .mapValues(lambda listOfTuple:list(listOfTuple))\n",
    "                       .collectAsMap()\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dimensional-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUserInfo(pair):\n",
    "    user = pair[0]\n",
    "    bus = pair[1]\n",
    "    user_avg = user_avg_dict.get(user, ALL_USER_AVG_RATING)\n",
    "    bus_avg = bus_avg_dict.get(bus, ALL_BUS_AVG_RATING)\n",
    "    feature_list = [user_avg, bus_avg]\n",
    "    \n",
    "    info_tuple = user_info_dict.get(user, default_tuple)\n",
    "    for feature in info_tuple:\n",
    "        feature_list.append(feature) \n",
    "\n",
    "    user_num_rating = len(uidx_star_dict.get(user, []))\n",
    "    bus_num_rating = len(bidx_star_dict.get(bus, []))\n",
    "    feature_list.append(user_num_rating)\n",
    "    feature_list.append(bus_num_rating)\n",
    "    feature_list.append(pair[2]) # the rating\n",
    "    \n",
    "    return tuple(feature_list)\n",
    "\n",
    "uidx_bidx_star_xgb = (jsonLine_rdd.map(lambda jLine: (uid2idx_dict[jLine[\"user_id\"]],\n",
    "                                                      bid2idx_dict[jLine[\"business_id\"]], \n",
    "                                                      jLine[\"stars\"]\n",
    "                                                     )\n",
    "                                      )\n",
    "                      .collect()\n",
    "                     )\n",
    "\n",
    "if use_test_gt:\n",
    "    gt_uidx_bidx_star_xgb = (sc.textFile(test_groundtruth_path).map(lambda line:json.loads(line))\n",
    "                            .map(lambda jLine: (uid2idx_dict.get(jLine[\"user_id\"], jLine[\"user_id\"]),\n",
    "                                                bid2idx_dict.get(jLine[\"business_id\"], jLine[\"business_id\"]), \n",
    "                                                jLine[\"stars\"]\n",
    "                                                )\n",
    "                                          )\n",
    "                          .collect()\n",
    "                         )\n",
    "    uidx_bidx_star_xgb.extend(gt_uidx_bidx_star_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "incredible-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert uidx and bidx to avg rating and keep the original rating\n",
    "xgboost_training_data = list()\n",
    "for pair in uidx_bidx_star_xgb:\n",
    "    train_tuple = getUserInfo(pair)\n",
    "    xgboost_training_data.append(train_tuple)\n",
    "\n",
    "train_data_df = pd.DataFrame(xgboost_training_data, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "civic-sullivan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, eta=0.47, gamma=0,\n",
       "             gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.469999999, max_delta_step=0, max_depth=8,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=12, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgboost.XGBRegressor(booster='gbtree', max_depth=8, eta=0.47)\n",
    "model.fit(X=train_data_df.iloc[:,:-1], y=train_data_df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "enhanced-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(xgb_model_output_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "thirty-territory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 533.1412658691406\n"
     ]
    }
   ],
   "source": [
    "print('Duration:', str(time.time()-startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-gnome",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
